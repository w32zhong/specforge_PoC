{"accept_lens.max": 7, "accept_lens.sum": 6765, "accept_lens_100samples": [1, 3, 1, 4, 4, 2, 1, 2, 3, 7, 3, 3, 5, 4, 4, 6, 2, 6, 2, 4, 5, 3, 4, 1, 3, 1, 3, 5, 1, 5, 4, 4, 6, 2, 4, 4, 5, 2, 5, 4, 7, 4, 4, 5, 4, 6, 1, 3, 1, 1, 2, 5, 5, 6, 2, 2, 2, 2, 4, 3, 2, 2, 3, 1, 1, 4, 1, 2, 3, 3, 3, 5, 6, 6, 2, 4, 3, 3, 3, 2, 3, 3, 5, 6, 2, 2, 1, 1, 3, 3, 4, 3, 7, 2, 3, 2, 3, 3, 2, 3], "accept_lens_freqs": {"1": 268, "2": 440, "3": 419, "4": 305, "5": 200, "6": 100, "7": 220}, "argv": ["meta-llama/Llama-2-7b-chat-hf", "--draft_model", "lmsys/sglang-EAGLE-llama2-chat-7B", "--dtype", "bfloat16", "--disable_cuda_graph", "True", "--speculative_algorithm", "EAGLE", "--speculative_tree", "6,10,60", "--bs", "1", "--tp_size", "2", "--max_new_tokens", "2048", "--mtbench", "question.jsonl:10", "--stream_if_bs1", "--outfile", "./output/meta-llama_Llama-2-7b-chat-hf--draft_modellmsys_sglang-EAGLE-llama2-chat-7B_acceptlens_histogram.log"], "avg_accept_len": 3.466, "completion_tokens": 6765, "scheduler_avg_accept_len": 3.453, "spec_verify_ct": 1952, "throughputs": 82.712, "time_cost": 81.79}
